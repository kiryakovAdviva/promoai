Фаза 1: Ремонт Ранжирования и Базовая Оценка
Исправить score_chunk:
Не отбрасывать семантику: Передавайте в score_chunk не только чанк, но и его изначальный семантический скор от FAISS (score из index.search).
Комбинировать оценки: Вместо простого сложения бонусов, комбинируйте семантический скор с эвристикой. Пример простого подхода: final_score = semantic_score * (1 + weight * normalized_heuristic_score). Здесь semantic_score – базовая релевантность, normalized_heuristic_score – ваша сумма бонусов, приведенная к диапазону (например, 0-1), weight – коэффициент влияния эвристики. Начните с малого weight (e.g., 0.1-0.3). Это самое важное изменение.
Нормализовать бонусы: Приведите сумму ваших бонусных баллов к предсказуемому диапазону перед умножением.
Пересмотреть веса бонусов: Начните с более простой схемы. Оставьте бонусы за тип запроса (query_type), явные совпадения ключевых метаданных (контакты для запроса контактов, SLA для SLA и т.д.) и бонус за известные ссылки (KEY_LINK_KEYWORDS). Остальные пока можно уменьшить или убрать для чистоты эксперимента.
Логирование: В log_interaction добавьте логирование изначального семантического скора рядом с кастомным скором, чтобы видеть, как переранжирование меняет порядок.
Тестирование с Сильной LLM:
Проводите тесты, используя Google Gemini 1.5 Flash (если есть ключ). Это поможет понять, связаны ли проблемы с качеством поиска/ранжирования или с ограничениями Mistral-7B.
Анализ Ранжирования:
Для нескольких типовых запросов (поиск контакта, SLA, процесса, ссылки) смотрите в логах:
Какие топ-20 чанков вернул FAISS (семантический поиск)?
Как изменился их порядок после вашего исправленного score_chunk?
Почему некоторые чанки поднялись/опустились? Соответствует ли это ожидаемой релевантности?
Проверка context_rules.py:
Пройдитесь по регулярным выражениям в context_rules.py и extract_meta в utils.py. Сверьте их с примерами из ваших PDF-документов. Найдите, что они пропускают или где ошибаются. Скорректируйте паттерны. Добавьте больше синонимов/вариантов в списки (отделы, роли, этапы).
Фаза 2: Улучшение Чанкинга и Метаданных
Оптимизировать process_document (utils.py):
PDF: Попробуйте извлекать и чанкить текст постранично, а не склеивать весь документ. Это сохранит локальный контекст и позволит точнее указывать страницу.
Контекст таблиц: Попробуйте добавлять 1-2 предложения до и после таблицы к тексту табличного чанка (в поле text), чтобы дать LLM больше контекста.
Параметры RecursiveCharacterTextSplitter: Поэкспериментируйте с chunk_size (попробуйте чуть больше, например, 1000) и chunk_overlap (200-250), если чанки кажутся слишком фрагментированными.
Перегенерировать чанки: После изменений запустите run_processing.py и run_embedder.py.
Доработать context_rules.py:
Продолжайте улучшать regex и списки на основе анализа документов.
Если regex становится слишком сложным, рассмотрите использование простых словарей для известных сущностей (ключевые сотрудники, отделы, проекты, инструменты) для более надежного извлечения.
Фаза 3: Оптимизация Промпта и Обфускации
Адаптация Промпта:
Если вы продолжаете использовать Mistral-7B, попробуйте упростить промпт в generate_bot_response. Сделайте инструкции короче и четче.
Проверьте, следует ли LLM инструкции по ссылкам (использует ли отдельный блок, дает ли только по запросу). Если нет, переформулируйте эту часть промпта.
Оценка Обфускации:
Протестируйте запросы, которые касаются сущностей, попадающих под обфускацию (например, "расскажи про Asana", "кто отвечает за проект Mostbet").
Если обфускация мешает, уточните regex в encryptor_tools.py, чтобы они были точнее, или исключите из обфускации определенные типы (например, tool).
Фаза 4: Дальнейшее Развитие (Опционально)
Продвинутое Ранжирование: Если эвристики недостаточно, изучите использование моделей-реранкеров (cross-encoders), которые напрямую сравнивают запрос и текст чанка для более точной оценки релевантности (но это потребует больше вычислений).
NER: Внедрите полноценную модель Named Entity Recognition (например, на базе Natasha или DeepPavlov, если нужны локальные решения) для извлечения метаданных вместо regex.
Анализ Структуры: Используйте заголовки и разделы документа для более осмысленного чанкинга.
