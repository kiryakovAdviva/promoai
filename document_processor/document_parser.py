# --- START OF FILE document_parser.py ---
import os
import sys
import traceback
from typing import Any, Dict, List, Optional, Tuple, Generator

import pandas as pd
import pdfplumber
import docx
from tqdm import tqdm
# import openpyxl # –ù–µ –Ω—É–∂–µ–Ω —è–≤–Ω—ã–π –∏–º–ø–æ—Ä—Ç, pandas –µ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
# –ï—Å–ª–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç–µ –Ω–µ –∫–∞–∫ –ø–∞–∫–µ—Ç, –∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ 'from common_utils import ...'
try:
    from .common_utils import clean_text, format_table_to_markdown
except ImportError:
    # –ü—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç –¥–ª—è —Å–ª—É—á–∞—è –ø–ª–æ—Å–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–æ–≤
    try:
        from common_utils import clean_text, format_table_to_markdown
        print("‚úÖ common_utils imported directly into document_parser.")
    except ImportError as e:
        sys.stderr.write(f"‚ùå CRITICAL: Failed to import common_utils in document_parser. Error: {e}\n")
        sys.exit(1)

# --- –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö "—Å—ã—Ä—ã—Ö" –±–ª–æ–∫–æ–≤ ---
class RawContentBlock:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å—ã—Ä–æ–≥–æ –±–ª–æ–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞."""
    def __init__(self, type: str, content: Any, source_info: Dict):
        self.type: str = type # 'text', 'table', 'excel_row'
        self.content: Any = content # str –¥–ª—è —Ç–µ–∫—Å—Ç–∞, List[Dict] –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã, Dict –¥–ª—è —Å—Ç—Ä–æ–∫–∏ Excel
        self.source_info: Dict = source_info # page_number, element_index, headers, etc.

    def __repr__(self):
        content_len_str = 'N/A'
        if isinstance(self.content, (str, list, dict)):
            try:
                content_len_str = str(len(self.content))
            except TypeError:
                pass # –ù–µ —É –≤—Å–µ—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –µ—Å—Ç—å len
        return (f"RawContentBlock(type='{self.type}', "
                f"source='{self.source_info.get('document_name', 'Unknown')}', "
                f"page={self.source_info.get('page_number', 'N/A')}, "
                f"content_len={content_len_str})")

# --- PDF Parser ---
def parse_pdf(file_path: str) -> Generator[RawContentBlock, None, None]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏ —Ç–∞–±–ª–∏—Ü—ã –∏–∑ PDF –∫–∞–∫ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä RawContentBlock."""
    document_name = os.path.basename(file_path)
    all_pdf_hyperlinks = []
    try:
        with pdfplumber.open(file_path) as pdf:
            # –°–Ω–∞—á–∞–ª–∞ —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –≥–∏–ø–µ—Ä—Å—Å—ã–ª–∫–∏
            for p_idx, page in enumerate(pdf.pages):
                try:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∞—Ç—Ä–∏–±—É—Ç–∞ hyperlinks –ø–µ—Ä–µ–¥ –¥–æ—Å—Ç—É–ø–æ–º
                    if hasattr(page, 'hyperlinks') and page.hyperlinks:
                        all_pdf_hyperlinks.extend([
                            {'url': link.get('uri'), 'page': p_idx + 1, 'text': link.get('title', '')}
                            for link in page.hyperlinks if link.get('uri') # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å URL
                        ])
                except Exception as e:
                    sys.stderr.write(f"  ‚ö†Ô∏è PDF link extraction error p.{p_idx+1} in '{document_name}': {e}\n")
            # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Å—Å—ã–ª–æ–∫ –ø–æ URL
            unique_hyperlinks = list({link['url']: link for link in all_pdf_hyperlinks}.values())
            print(f"  üîó PDF Links found in '{document_name}': {len(unique_hyperlinks)}")

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            for i, page in enumerate(tqdm(pdf.pages, desc=f"  -> PDF Pages '{document_name}'", unit="page", leave=False)):
                page_num = i + 1
                # –ì–∏–ø–µ—Ä—Å—Å—ã–ª–∫–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                page_hyperlinks = [h for h in unique_hyperlinks if h.get('page') == page_num]

                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã
                try:
                    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–∂–Ω–æ –ø–æ–¥–±–∏—Ä–∞—Ç—å –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                    tables = page.extract_tables({
                        "vertical_strategy": "lines",
                        "horizontal_strategy": "lines",
                        "intersection_tolerance": 3, # –£–º–µ–Ω—å—à–∏–ª –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
                        "snap_tolerance": 3,
                    })
                    if tables:
                        for table_idx, table_raw in enumerate(tables):
                            if not table_raw or len(table_raw) < 1: continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Ç–∞–±–ª–∏—Ü—ã

                            # –û—á–∏—â–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏, –∑–∞–º–µ–Ω—è–µ–º None/–ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –Ω–∞ Col_N
                            headers = [clean_text(h) if h and clean_text(h) else f"Col_{j}" for j, h in enumerate(table_raw[0])]
                            table_data: List[Dict[str, Any]] = []

                            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –¥–∞–Ω–Ω—ã—Ö (–Ω–∞—á–∏–Ω–∞—è —Å–æ –≤—Ç–æ—Ä–æ–π —Å—Ç—Ä–æ–∫–∏)
                            if len(table_raw) > 1:
                                for row_cells in table_raw[1:]:
                                    if not row_cells: continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
                                    # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–æ–ª-–≤–æ —è—á–µ–µ–∫ —Å –∫–æ–ª-–≤–æ–º –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
                                    processed_cells = row_cells[:len(headers)] + [''] * (len(headers) - len(row_cells))
                                    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å, –æ—á–∏—â–∞—è –∑–Ω–∞—á–µ–Ω–∏—è, –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ —è—á–µ–π–∫–∏
                                    row_dict = {
                                        headers[j]: clean_text(cell)
                                        for j, cell in enumerate(processed_cells) if cell is not None and clean_text(str(cell)) # –¢–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ —è—á–µ–π–∫–∏ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
                                    }
                                    if row_dict: # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤ –Ω–µ–π –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ
                                        table_data.append(row_dict)

                            # –û—Ç–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ –¥–∞–Ω–Ω—ã–µ
                            if headers and table_data:
                                source_info = {
                                    "document_name": document_name,
                                    "page_number": page_num,
                                    "table_index_on_page": table_idx + 1, # 1-based index
                                    "headers": headers,
                                    "document_hyperlinks": unique_hyperlinks # –ü–µ—Ä–µ–¥–∞–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                                }
                                yield RawContentBlock(type='table', content=table_data, source_info=source_info)
                            elif headers and not table_data:
                                print(f"    ‚ÑπÔ∏è PDF Table on p.{page_num} has headers but no data. Skipping.")
                            # else: # –°–ª—É—á–∞–π: –Ω–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö (–∏–ª–∏ –∏ —Ç–æ –∏ –¥—Ä—É–≥–æ–µ)
                                # print(f"    ‚ÑπÔ∏è PDF Table on p.{page_num} is empty or lacks headers. Skipping.")

                except Exception as e:
                    sys.stderr.write(f"  ‚ö†Ô∏è PDF table extraction error p.{page_num} in '{document_name}': {e}\n")
                    # traceback.print_exc() # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏

                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç (–ø–æ—Å–ª–µ —Ç–∞–±–ª–∏—Ü, —Ç.–∫. extract_text –º–æ–∂–µ—Ç –≤–∫–ª—é—á–∞—Ç—å —Ç–µ–∫—Å—Ç —Ç–∞–±–ª–∏—Ü)
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º x_tolerance –∏ y_tolerance –¥–ª—è –ª—É—á—à–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                page_text_raw = page.extract_text(x_tolerance=2, y_tolerance=3, layout=False, keep_blank_chars=False)
                page_text_cleaned = clean_text(page_text_raw)

                # –û—Ç–¥–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –±–ª–æ–∫, –µ—Å–ª–∏ –æ–Ω –Ω–µ –ø—É—Å—Ç–æ–π
                if page_text_cleaned:
                    source_info = {
                        "document_name": document_name,
                        "page_number": page_num,
                        "document_hyperlinks": unique_hyperlinks # –ü–µ—Ä–µ–¥–∞–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                        # "page_hyperlinks": page_hyperlinks # –ú–æ–∂–Ω–æ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å —Å—Å—ã–ª–∫–∏ —Ç–æ–ª—å–∫–æ –¥–ª—è —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    }
                    yield RawContentBlock(type='text', content=page_text_cleaned, source_info=source_info)

    except Exception as e:
        sys.stderr.write(f"‚ùå CRITICAL PDF Error processing '{document_name}': {e}\n")
        traceback.print_exc()

# --- DOCX Parser ---
def parse_docx(file_path: str) -> Generator[RawContentBlock, None, None]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏ —Ç–∞–±–ª–∏—Ü—ã –∏–∑ DOCX –∫–∞–∫ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä RawContentBlock."""
    document_name = os.path.basename(file_path)
    unique_hyperlinks_docx = [] # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –≥–∏–ø–µ—Ä—Å—Å—ã–ª–æ–∫ DOCX
    # print(f"  üîó DOCX links extraction not implemented yet for '{document_name}'.") # –£–±—Ä–∞–ª –≤—ã–≤–æ–¥

    try:
        doc = docx.Document(file_path)
        body_elements = list(doc.element.body) # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ—á–µ—Ä–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã body
        current_heading = "–û–±—â–µ–µ"
        current_text_accumulator = ""

        for idx, element in enumerate(tqdm(body_elements, desc=f"  -> DOCX Elements '{document_name}'", unit="elem", leave=False)):
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —ç–ª–µ–º–µ–Ω—Ç–∞ (–ø–∞—Ä–∞–≥—Ä–∞—Ñ –∏–ª–∏ —Ç–∞–±–ª–∏—Ü–∞)
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º local-name() –¥–ª—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–µ—Ñ–∏–∫—Å–∞ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –∏–º–µ–Ω (w:)
            is_paragraph = hasattr(element, 'xpath') and ('p' in element.xpath('local-name(.)'))
            is_table = hasattr(element, 'xpath') and ('tbl' in element.xpath('local-name(.)'))

            if is_paragraph:
                try:
                    # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç Paragraph –∏–∑ —ç–ª–µ–º–µ–Ω—Ç–∞
                    p = docx.text.paragraph.Paragraph(element, doc)
                    para_text = clean_text(p.text)

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∏–ª—å –Ω–∞ –∑–∞–≥–æ–ª–æ–≤–æ–∫ (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ)
                    style_name = p.style.name.lower() if p.style and p.style.name else ""
                    is_heading_style = style_name.startswith(('heading', '–∑–∞–≥–æ–ª–æ–≤–æ–∫', 'title', '–Ω–∞–∑–≤–∞–Ω–∏–µ'))

                    # –ï—Å–ª–∏ —ç—Ç–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –æ–Ω –Ω–µ –ø—É—Å—Ç–æ–π
                    if is_heading_style and para_text:
                        # –ï—Å–ª–∏ –±—ã–ª –Ω–∞–∫–æ–ø–ª–µ–Ω —Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–¥ —ç—Ç–∏–º –∑–∞–≥–æ–ª–æ–≤–∫–æ–º, –æ—Ç–¥–∞–µ–º –µ–≥–æ
                        if current_text_accumulator.strip():
                            source_info = {
                                "document_name": document_name,
                                "current_heading": current_heading, # –ó–∞–≥–æ–ª–æ–≤–æ–∫, –∫ –∫–æ—Ç–æ—Ä–æ–º—É –æ—Ç–Ω–æ—Å–∏–ª—Å—è —Ç–µ–∫—Å—Ç
                                "document_hyperlinks": unique_hyperlinks_docx
                            }
                            yield RawContentBlock(type='text', content=current_text_accumulator.strip(), source_info=source_info)

                        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä —Ç–µ–∫—Å—Ç–∞
                        current_heading = para_text
                        current_text_accumulator = "" # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π –±–ª–æ–∫ —Ç–µ–∫—Å—Ç–∞ –ø–æ–¥ –Ω–æ–≤—ã–º –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
                        # print(f"\n    --- DOCX Heading Found: '{current_heading}' ---") # –£–±—Ä–∞–ª –≤—ã–≤–æ–¥
                    # –ï—Å–ª–∏ —ç—Ç–æ –æ–±—ã—á–Ω—ã–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ —Å —Ç–µ–∫—Å—Ç–æ–º
                    elif para_text:
                        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ –∫ –∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä—É, —Ä–∞–∑–¥–µ–ª—è—è –¥–≤–æ–π–Ω—ã–º –ø–µ—Ä–µ–Ω–æ—Å–æ–º
                        current_text_accumulator += para_text + "\n\n"

                except Exception as e:
                    # –õ–æ–≤–∏–º –æ—à–∏–±–∫–∏ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞
                    sys.stderr.write(f"  ‚ö†Ô∏è DOCX Paragraph processing error (element {idx}) in '{document_name}': {e}\n")
                    continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç–æ—Ç –ø–∞—Ä–∞–≥—Ä–∞—Ñ

            elif is_table:
                # –ü–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Ç–∞–±–ª–∏—Ü—ã –æ—Ç–¥–∞–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –±–ª–æ–∫
                if current_text_accumulator.strip():
                    source_info = {
                        "document_name": document_name,
                        "current_heading": current_heading,
                        "document_hyperlinks": unique_hyperlinks_docx
                    }
                    yield RawContentBlock(type='text', content=current_text_accumulator.strip(), source_info=source_info)
                    current_text_accumulator = "" # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
                # print(f"    --- DOCX Table Found (element index {idx}) ---") # –£–±—Ä–∞–ª –≤—ã–≤–æ–¥
                try:
                    table_obj = docx.table.Table(element, doc)
                    if not table_obj.rows:
                         # print("      Skipping empty table (no rows).") # –£–±—Ä–∞–ª –≤—ã–≤–æ–¥
                         continue

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏–∑ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏, –æ—á–∏—â–∞—è –∏—Ö
                    headers = [clean_text(cell.text) for cell in table_obj.rows[0].cells]
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ä–µ–∞–ª—å–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ (–Ω–µ –ø—É—Å—Ç—ã–µ –∏ –Ω–µ –ø—Ä–æ—Å—Ç–æ 'Col_N')
                    has_actual_headers = any(h for h in headers)
                    start_row_index = 1 if has_actual_headers else 0

                    # –ï—Å–ª–∏ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –Ω–µ—Ç, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏—Ö –∫–∞–∫ Col_N
                    if not has_actual_headers:
                         num_cols = len(table_obj.rows[0].cells) if table_obj.rows else 0
                         if num_cols == 0: continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ –∏ –∫–æ–ª–æ–Ω–æ–∫ –Ω–µ—Ç
                         headers = [f"Col_{j}" for j in range(num_cols)]
                         start_row_index = 0 # –ù–∞—á–∏–Ω–∞–µ–º —Å –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏, —Ä–∞–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –Ω–µ –±—ã–ª–æ

                    table_data: List[Dict[str, Any]] = []
                    # –ò—Ç–µ—Ä–∏—Ä—É–µ–º—Å—è –ø–æ —Å—Ç—Ä–æ–∫–∞–º –¥–∞–Ω–Ω—ã—Ö
                    for r_idx, row in enumerate(table_obj.rows[start_row_index:], start=start_row_index):
                        row_values = [clean_text(cell.text) for cell in row.cells]
                        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Å—Ç—Ä–æ–∫–∏, –æ–±—Ä–µ–∑–∞—è –ª–∏—à–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–ª–∏ –¥–æ–ø–æ–ª–Ω—è—è –ø—É—Å—Ç—ã–º–∏
                        # –í–∫–ª—é—á–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ —è—á–µ–π–∫–∏ –≤ —Å–ª–æ–≤–∞—Ä—å
                        row_dict = {
                            headers[j]: val
                            for j, val in enumerate(row_values)
                            if j < len(headers) and val # –£—Å–ª–æ–≤–∏–µ: –∏–Ω–¥–µ–∫—Å –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–µ –ø—É—Å—Ç–æ–µ
                        }
                        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ö–æ—Ç—å –∫–∞–∫–∏–µ-—Ç–æ –¥–∞–Ω–Ω—ã–µ
                        if row_dict:
                            table_data.append(row_dict)

                    # –û—Ç–¥–∞–µ–º –±–ª–æ–∫ —Ç–∞–±–ª–∏—Ü—ã, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ
                    if table_data:
                         source_info = {
                             "document_name": document_name,
                             "table_index_in_doc": idx + 1, # 1-based index
                             "current_heading": current_heading, # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å–µ–∫—Ü–∏–∏, –≥–¥–µ —Ç–∞–±–ª–∏—Ü–∞
                             "headers": headers,
                             "document_hyperlinks": unique_hyperlinks_docx
                         }
                         yield RawContentBlock(type='table', content=table_data, source_info=source_info)
                         # print(f"      Table {idx+1} processed successfully.") # –£–±—Ä–∞–ª –≤—ã–≤–æ–¥
                    # else:
                        # print(f"      Table {idx+1} resulted in no data after processing, skipping.") # –£–±—Ä–∞–ª –≤—ã–≤–æ–¥

                except Exception as e:
                    sys.stderr.write(f"  ‚ö†Ô∏è DOCX Table processing error (element {idx}) in '{document_name}': {e}\n")
                    traceback.print_exc() # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏

            else:
                # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø —ç–ª–µ–º–µ–Ω—Ç–∞ –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                # print(f"  ‚ÑπÔ∏è Skipping unknown top-level element (index {idx}) in '{document_name}'")
                pass

        # –ü–æ—Å–ª–µ —Ü–∏–∫–ª–∞ –æ—Ç–¥–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –±–ª–æ–∫, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        if current_text_accumulator.strip():
            source_info = {
                "document_name": document_name,
                "current_heading": current_heading,
                "document_hyperlinks": unique_hyperlinks_docx
            }
            yield RawContentBlock(type='text', content=current_text_accumulator.strip(), source_info=source_info)

        # print(f"  Finished iterating through DOCX elements for '{document_name}'.") # –£–±—Ä–∞–ª –≤—ã–≤–æ–¥

    except Exception as e:
        # –õ–æ–≤–∏–º –æ—à–∏–±–∫–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ –æ—Ç–∫—Ä—ã—Ç–∏—è/–æ—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ DOCX
        sys.stderr.write(f"‚ùå CRITICAL DOCX Error processing '{document_name}': {e}\n")
        traceback.print_exc()

# --- Excel Parser (v17 - Refined, using RawContentBlock) ---
def parse_excel(xlsx_path: str) -> Generator[RawContentBlock, None, None]:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç Excel —Ñ–∞–π–ª, –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—è –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ RawContentBlock 'excel_row'."""
    document_name = os.path.basename(xlsx_path)
    # print(f"üìÑ Processing Excel file: {document_name}") # –£–±—Ä–∞–ª –≤—ã–≤–æ–¥
    try:
        # engine=None –ø–æ–∑–≤–æ–ª—è–µ—Ç pandas –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±—Ä–∞—Ç—å (–æ–±—ã—á–Ω–æ openpyxl)
        xls = pd.ExcelFile(xlsx_path, engine=None)
        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –ª–∏—Å—Ç–∞–º
        for sheet_name in tqdm(xls.sheet_names, desc=f"  -> Excel Sheets '{document_name}'", unit="sheet", leave=False):
            # print(f"  -- Processing sheet: '{sheet_name}'") # –£–±—Ä–∞–ª –≤—ã–≤–æ–¥
            df: pd.DataFrame
            headers: List[str] = []
            header_row_index = 0 # –ò–Ω–¥–µ–∫—Å —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—É—é –º—ã —Å—á–∏—Ç–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–æ–º (0-based)
            try:
                # --- –ß—Ç–µ–Ω–∏–µ –∏ –ø–æ–∏—Å–∫ –∑–∞–≥–æ–ª–æ–≤–∫–∞ ---
                # 1. –ß–∏—Ç–∞–µ–º –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞, —á—Ç–æ–±—ã –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏
                #    dtype=str —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö pandas
                df_raw = pd.read_excel(xlsx_path, sheet_name=sheet_name, header=None, dtype=str).fillna('')
                if df_raw.empty:
                    # print(f"    Sheet '{sheet_name}' is empty. Skipping.") # –£–±—Ä–∞–ª –≤—ã–≤–æ–¥
                    continue

                # 2. –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –≤ –ø–µ—Ä–≤—ã—Ö N —Å—Ç—Ä–æ–∫–∞—Ö (–Ω–∞–ø—Ä., 5)
                potential_header_row = -1 # –ò–Ω–¥–µ–∫—Å —Å—Ç—Ä–æ–∫–∏-–∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∏
                max_keywords_found = 1 # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª-–≤–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è –ø—Ä–∏–∑–Ω–∞–Ω–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
                keywords = {"position", "email", "tg", "telegram", "–æ—Ç–¥–µ–ª", "department",
                            "name", "–∏–º—è", "—Ñ–∞–º–∏–ª–∏—è", "–¥–æ–ª–∂–Ω–æ—Å—Ç—å", "fi", "team", "–∫–æ–º–∞–Ω–¥–∞",
                            "geo", "—Å—Å—ã–ª–∫–∞", "—Ñ–æ—Ä–º–∞", "–Ω–∞–∑–≤–∞–Ω–∏–µ", "–æ–ø–∏—Å–∞–Ω–∏–µ", "–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π",
                            "responsible", "role", "—Ä–æ–ª—å", "contact", "–∫–æ–Ω—Ç–∞–∫—Ç", "status", "—Å—Ç–∞—Ç—É—Å"}

                for r_idx in range(min(5, len(df_raw))):
                    row_values = [str(c).lower().strip() for c in df_raw.iloc[r_idx].values if str(c).strip()]
                    if not row_values: continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
                    row_text = " ".join(row_values)
                    keywords_found = sum(1 for kw in keywords if kw in row_text)

                    # –°—á–∏—Ç–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–æ–º, –µ—Å–ª–∏ –Ω–∞—à–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
                    if keywords_found >= max_keywords_found:
                         potential_header_row = r_idx
                         max_keywords_found = keywords_found # –û–±–Ω–æ–≤–ª—è–µ–º –º–∞–∫—Å. –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö (–º–æ–∂–Ω–æ —É–±—Ä–∞—Ç—å –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã)
                         break # –ù–∞—à–ª–∏ –ø–µ—Ä–≤—ã–π –ø–æ–¥—Ö–æ–¥—è—â–∏–π - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ

                # 3. –ü–µ—Ä–µ—á–∏—Ç—ã–≤–∞–µ–º DataFrame —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º –∑–∞–≥–æ–ª–æ–≤–∫–æ–º –∏–ª–∏ –±–µ–∑ –Ω–µ–≥–æ
                if potential_header_row != -1:
                    header_row_index = potential_header_row
                    # print(f"    Detected header row index: {header_row_index}") # –£–±—Ä–∞–ª –≤—ã–≤–æ–¥
                    # –ß–∏—Ç–∞–µ–º —Å–Ω–æ–≤–∞, –∏—Å–ø–æ–ª—å–∑—É—è –Ω–∞–π–¥–µ–Ω–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫, dtype=str
                    df = pd.read_excel(xlsx_path, sheet_name=sheet_name, header=header_row_index, dtype=str).fillna('')
                else:
                    # print(f"    ‚ö†Ô∏è Could not detect header row. Reading without header.") # –£–±—Ä–∞–ª –≤—ã–≤–æ–¥
                    df = df_raw # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã–π df_raw
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ "Col_N"
                    df.columns = [f"Col_{i}" for i in range(len(df.columns))]

                # print(f"    Read {len(df)} data rows from sheet '{sheet_name}'.") # –£–±—Ä–∞–ª –≤—ã–≤–æ–¥
                if df.empty: continue

                # --- –û—á–∏—Å—Ç–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ DataFrame ---
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏: –≤ –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä, —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã, –∑–∞–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã
                df.columns = [str(col).strip().lower().replace('\n', ' ').replace('\r', '') for col in df.columns]
                # –£–¥–∞–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ 'unnamed:' –æ—Ç pandas
                original_columns = list(df.columns)
                df = df.loc[:, ~df.columns.str.startswith('unnamed:')]
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Å—Ç–∞–ª–∏—Å—å –ª–∏ –∫–æ–ª–æ–Ω–∫–∏
                if df.empty:
                    # print(f"    No valid columns left after removing 'unnamed:' for sheet '{sheet_name}'. Skipping.") # –£–±—Ä–∞–ª –≤—ã–≤–æ–¥
                     continue
                headers = list(df.columns)
                # print(f"    Using headers: {headers}") # –£–±—Ä–∞–ª –≤—ã–≤–æ–¥

            except Exception as e:
                sys.stderr.write(f"  ‚ùå ERROR reading/processing sheet '{sheet_name}' in '{document_name}': {e}\n")
                traceback.print_exc()
                continue # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –ª–∏—Å—Ç—É

            # --- –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–æ–∫ ---
            # –ò—Ç–µ—Ä–∏—Ä—É–µ–º—Å—è –ø–æ —Å—Ç—Ä–æ–∫–∞–º DataFrame
            for index, row in df.iterrows():
                # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –∫–ª—é—á - –∑–∞–≥–æ–ª–æ–≤–æ–∫, –∑–Ω–∞—á–µ–Ω–∏–µ - —Ç–µ–∫—Å—Ç —è—á–µ–π–∫–∏ (–æ—á–∏—â–µ–Ω–Ω—ã–π)
                # –í–∫–ª—é—á–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ —è—á–µ–π–∫–∏
                row_dict_cleaned = {
                    str(k): clean_text(str(v))
                    for k, v in row.to_dict().items()
                    if str(v).strip() # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–µ –ø—É—Å—Ç–æ–µ *–¥–æ* –æ—á–∏—Å—Ç–∫–∏ clean_text
                }

                # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –æ–∫–∞–∑–∞–ª–∞—Å—å –ø—É—Å—Ç–æ–π –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—ë
                if not row_dict_cleaned:
                    continue

                # –û—Ç–¥–∞–µ–º –∫–∞–∂–¥—É—é –Ω–µ–ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–π –±–ª–æ–∫
                source_info = {
                    "document_name": document_name,
                    "sheet_name": sheet_name,
                    # –†–µ–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏ –≤ Excel: index –∏–∑ df + –Ω–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞ + 1 (—Ç.–∫. index —Å 0) + 1 (—Ç.–∫. Excel —Å 1)
                    "row_index_excel": index + header_row_index + 1,
                    "headers": headers, # –ü–µ—Ä–µ–¥–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Ç–∞–±–ª–∏—Ü—ã/–ª–∏—Å—Ç–∞
                    "document_hyperlinks": [] # –°—Å—ã–ª–∫–∏ –±—É–¥—É—Ç –∏–∑–≤–ª–µ—á–µ–Ω—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                }
                yield RawContentBlock(type='excel_row', content=row_dict_cleaned, source_info=source_info)

    except ImportError as e:
         sys.stderr.write(f"‚ùå CRITICAL Excel Error: Missing library for '{xlsx_path}'. Install 'openpyxl' (for .xlsx) or 'xlrd' (for .xls). Error: {e}\n")
    except Exception as e:
        sys.stderr.write(f"‚ùå CRITICAL Excel Error processing '{document_name}': {e}\n")
        traceback.print_exc()
    # print(f"‚úÖ Finished processing Excel: {document_name}") # –£–±—Ä–∞–ª –≤—ã–≤–æ–¥

# --- –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è-–¥–∏—Å–ø–µ—Ç—á–µ—Ä ---
def parse_document(file_path: str) -> Generator[RawContentBlock, None, None]:
    """
    –í—ã–±–∏—Ä–∞–µ—Ç –Ω—É–∂–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä RawContentBlock.
    """
    extension = file_path.split(".")[-1].lower()
    document_name = os.path.basename(file_path)
    # print(f"üöÄ Starting parsing for: {document_name} ({extension.upper()})") # –£–±—Ä–∞–ª –≤—ã–≤–æ–¥

    if extension == "pdf":
        yield from parse_pdf(file_path)
    elif extension == "docx":
        yield from parse_docx(file_path)
    elif extension in ["xlsx", "xls"]: # –î–æ–±–∞–≤–∏–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∫—É xls (—Ç—Ä–µ–±—É–µ—Ç xlrd)
        yield from parse_excel(file_path)
    else:
        sys.stderr.write(f"‚ö†Ô∏è Unsupported file type skipped: {document_name}\n")
        return # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä (–∏–ª–∏ –º–æ–∂–Ω–æ 'yield from []')

# --- END OF FILE document_parser.py ---